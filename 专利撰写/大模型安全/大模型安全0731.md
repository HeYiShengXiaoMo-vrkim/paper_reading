## 标题
### **一种基于内部状态与外部语义协同感知的大语言模型动态安全监测方法**
## 摘要
本发明提出一种基于内部状态与外部语义协同感知的大语言模型动态安全监测方法。该方法首先通过外部语义感知模块对用户输入进行高风险意图分析，生成初始风险评分；其次，在模型推理时，通过内部状态监控模块实时监测其注意力分布熵和层激活范数等内部关键状态，生成内部异常评分；最后，***动态放行裁决模块***协同分析内外风险信号，结合预设的协同决策逻辑进行综合评判，并执行拦截、放行或告警等响应动作。本发明通过内外协同感知，有效解决了传统“黑箱”式防御无法应对语义隐晦攻击的问题，能显著提升对未知和复杂攻击的识别准确率与响应及时性。

**权利要求书：（下去再改一版）**

1. 一种基于内部状态与外部语义协同感知的大语言模型动态安全防御方法，其特征在于，所述方法包括以下步骤：  
第一步，对用户输入进行外部语义风险预处理，分析其是否存在恶意攻击意图，并生成初始风险评分；  
第二步，在主大语言模型处理用户输入并生成内容的过程中，实时监控其内部关键状态指标的异常，并生成内部异常评分；  
第三步，基于所述初始风险评分和内部异常评分，通过协同决策逻辑进行综合评判，并执行相应的动态响应动作。

2. 根据权利要求1所述的基于内部状态与外部语义协同感知的大语言模型动态安全防御方法，其特征在于，所述外部语义风险预处理步骤具体包括：  
在主大语言模型前端部署一个轻量级意图分类模型，用于分析所述用户输入是否包含指令冲突意图、角色扮演诱导意图以及假设情景规避意图中的至少一种；  
***根据所述意图分类模型的分析结果，生成量化的所述初始风险评分。（有点简单）***

3. 根据权利要求1所述的基于内部状态与外部语义协同感知的大语言模型动态安全防御方法，其特征在于，所述内部关键状态指标至少包括：  
注意力分布熵，通过在模型生成每个词元时，提取其自注意力层的权重矩阵并计算其香农熵以进行监控；  
层激活范数，通过在模型推理时，获取指定Transformer层的输出激活值并计算其 ***L2范数（稍微明确一点这个是什么）*** 以进行监控；  
所述内部异常评分是基于所述注意力分布熵和层激活范数与预设基线的偏离程度而生成的。

4. 根据权利要求1所述的基于内部状态与外部语义协同感知的大语言模型动态安全防御方法，其特征在于，所述协同决策逻辑具体包括：***（这块内容和发明说明书一样，要写公式，发明说明书和权要统一，把发明说明书相关内容补充一下，增加图相关的解释）***
当所述初始风险评分和内部异常评分均低于第一预设阈值时，判定为安全请求，允许模型正常输出；  
当所述初始风险评分和内部异常评分均高于第二预设阈值时，判定为高置信度攻击，立即中断模型的生成过程；  
当所述初始风险评分低于第一预设阈值而内部异常评分高于第二预设阈值时，判定为发现一种新型未知攻击，立即中断模型的生成过程，并将该用户输入与对应的内部状态指标标记为待分析样本；  
当所述初始风险评分高于第二预设阈值而内部异常评分低于第一预设阈值时，判定为模型已成功抵御潜在攻击，允许模型输出但进行日志记录。

5. 根据权利要求4所述的基于内部状态与外部语义协同感知的大语言模型动态安全防御方法，其特征在于，所述方法还包括防御系统自适应优化的步骤：  
将所述被标记为待分析样本的用户输入收集起来，形成一个攻击样本增强数据集；  
利用所述攻击样本增强数据集，对权利要求2中所述的轻量级意图分类模型进行重新训练或微调，以提升其对新型未知攻击的识别能力。

## 技术说明书

#### **【技术领域】**

[0001] 本发明属于人工智能安全技术领域，尤其涉及一种用于检测和防御针对大语言模型的恶意攻击，特别是提示注入和越狱攻击的系统及方法。

#### **【背景技术】**

[0002] 近年来，以Transformer架构为基础的大语言模型（LLM）取得了突破性进展，并在自然语言处理、代码生成、智能客服、内容创作等众多领域展现出巨大的应用潜力。然而，随着其能力的增强和应用的普及，其面临的安全威胁也日益严峻。

[0003] 目前，针对大语言模型的攻击主要表现为两种形式：一是提示注入，攻击者通过在用户输入中植入恶意指令，意图篡改或覆盖模型开发者预设的系统级指令，从而劫持模型的任务流，使其执行非预期甚至有害的操作。二是越狱，攻击者通过构建复杂的对话场景、进行角色扮演诱导或利用模型的逻辑漏洞，绕过其安全与道德准则，迫使其生成被禁止的内容，如暴力、歧视性言论或非法活动指南。

[0004] 现有技术方案普遍将大语言模型视作一个不可观测的“黑箱”，防御措施仅停留在其外部的文本流层面。这种方式无法感知到模型在处理恶意输入时，其内部计算状态发生的微妙而关键的变化。因此，当面对精心构造的、语义隐晦的复杂攻击时，这些防御手段往往显得力不从心，难以提供可靠、前瞻性的安全保障。

#### **【发明内容】**

[0005] 针对上述技术的不足，本发明的目的在于解决现有技术中存在的表层防御易被绕过、无法感知内部状态以及对未知攻击泛化能力差的问题。

[0006] 为实现上述目的，本发明采取的技术方案如下：

[0007] 所述一种基于内部状态与外部语义协同感知的大语言模型动态安全防御方法，包括以下步骤：***（跟权要对齐，一致就行）***

[0008] 第一步，对用户输入进行外部语义风险预处理。在用户输入送入主大语言模型前，通过一个配置于其前端的***预处理模块***对其进行语义意图分析。该模块内置一个轻量级意图分类模型，专门用于识别高风险攻击模式，如指令冲突意图、角色扮演诱导意图和假设情景规避意图等。分析后，生成一个量化的初始风险评分，作为外部语义风险的初步判断依据。

[0009] 第二步，对模型进行内部状态实时监控。在主模型进行推理生成的过程中，通过一个与主模型深度耦合的监控模块，实时捕捉由恶意输入引发的内部状态异常。具体地，本发明提出监控至少两种内部状态指标，其一为注意力分布熵，即在模型生成每个词元时提取其自注意力权重分布并计算香农熵，恶意指令通常导致该熵值显著低于正常基线；其二为层激活范数，即获取指定Transformer层的输出激活值并计算其范数，恶意输入常会激活罕见神经元导致该范数异常升高。该模块根据所监测到的指标偏离度，生成一个量化的内部异常评分。

[0010] 第三步，进行协同裁决与动态响应。将前述得到的初始风险评分和内部异常评分作为输入，通过一个作为决策中枢的裁决模块进行综合评判。该协同决策逻辑包括：当两个评分均较低时，判定为安全请求，允许模型正常输出；当两个评分均较高时，判定为高置信度攻击，立即中断生成过程并返回安全提示；当初始风险评分高而内部异常评分低时，判定为潜在攻击被成功抵御，可选择放行但进行日志记录；当初始风险评分低而内部异常评分高时，判定为发现一种语义隐蔽的新型未知攻击，应立即拦截，并将该样本用于防御系统的自适应优化。


[0011] 所述**预处理模块**中生成的**初始风险评分** $S_{ext}$，可以通过一个预训练的轻量级分类模型计算得出。该模型接收用户输入文本 $I$ ，并输出一个多维向量，每一维对应一种攻击意图的概率。初始风险评分可通过对这些概率进行加权求和或取最大值得到：
[0012]$$
S_{ext} = f(I; \theta_{cls})
$$
[0013]其中，$f(\cdot)$ 为分类模型，$I$ 为输入文本，$\theta_{cls}$ 为模型参数。评分 $S_{ext}$ 的取值范围被归一化到 [0, 1] 区间。

 [0014]所述**监控模块**中生成的**内部异常评分** $S_{int}$由多个内部指标的偏离度加权组合而成。***强调一下是输出的最后一层llm***
[0015]具体地，对于**注意力分布熵**，设模型在生成第 $t$ 个词元时的注意力权重分布为 $p_t$，其香农熵为 $H(p_t) = -\sum_i p_{t,i} \log p_{t,i}$。其偏离度 $D_{entropy}$ 可通过与正常基线熵均值 $\mu_H$ 和标准差 $\sigma_H$ 的Z-score计算得到：
$$
D_{entropy}(t) = \frac{|\mu_H - H(p_t)|}{\sigma_H}
$$
[0016]对于**层激活范数**，设第 $l$ 层的激活输出为 $A_l$，其L2范数为 $N(A_l) = ||A_l||_2$。其偏离度 $D_{norm}$ 可通过与正常基线范数均值 $\mu_N$ 和标准差 $\sigma_N$ 类似地计算。
[0017]最终的内部异常评分 $S_{int}$ 由各偏离度加权求和得到，并经过Sigmoid函数 $\sigma(\cdot)$ 归一化：
$$
S_{int}(t) = \sigma(w_{ent} \cdot D_{entropy}(t) + w_{norm} \cdot D_{norm}(t))
$$
其中，$w_{ent}$ 和 $w_{norm}$ 为预设权重，且 $w_{ent} + w_{norm} = 1$。

[0018] 可选地，所述**裁决模块**的协同决策逻辑可以通过一个动态决策函数或一个预定义的决策矩阵实现。
[0019]一种实现方式是计算一个**最终裁决分数** $S_{final}$：
[0020]$$
S_{final} = \lambda \cdot S_{ext} + (1-\lambda) \cdot \max_{t}(S_{int}(t))
$$
[0021]其中，$\lambda$ 为平衡外部语义风险与内部状态异常的权重因子，取值范围为 $\lambda \in [0.4, 0.6]$；$\max_{t}(S_{int}(t))$ 表示在整个生成过程中出现的最大内部异常评分。
[0022]裁决模块根据 $S_{final}$ 的值进行响应：
（a）当 $S_{final} < \theta_{low}$ 时，判定为安全请求，其中 $\theta_{low}$ 为低风险阈值，$\theta_{low} \in [0.3, 0.5]$；
（b）当 $S_{final} > \theta_{high}$ 时，判定为高置信度攻击，其中 $\theta_{high}$ 为高风险阈值，$\theta_{high} \in [0.8, 0.9]$；
（c）当 $\theta_{low} \le S_{final} \le \theta_{high}$ 时，系统可进入人工审核或更详细的分析流程。

[0023] 所述防御系统的**自适应优化**步骤具体如下：
[0024]首先，对于被判定为新型未知攻击的样本（即 $S_{ext}$ 低而 $S_{int}$ 高），系统自动将其输入文本和触发高异常评分的内部状态数据（如对应的注意力矩阵和激活值）打包存储。
[0025]接着，采用半监督学习或主动学习策略，由安全专家对一小部分标记样本进行确认，标注其具体的攻击类型。
[0026]然后，将这些经过确认的高价值负样本加入到预处理模块的训练数据集中，并采用在线学习或周期性微调的方式更新意图分类模型 $\theta_{cls}$ 的权重，更新公式可采用梯度下降：
[0027]$$
\theta_{cls}^{new} = \theta_{cls}^{old} - \eta \cdot \nabla_{\theta_{cls}} L(\theta_{cls}^{old})
$$
[0028]其中，$\eta$ 为学习率，$L(\cdot)$ 为交叉熵损失函数。通过此过程，防御系统能够持续学习并适应层出不穷的新型攻击手法。

#### **【附图说明】**

[0011] **图1** 为本发明所述的大语言模型动态安全防御系统的整体架构示意图。
[0012] **图2** 为本发明所述的协同裁决逻辑示意图。
[0013] **图3** 为本发明所述的未知攻击样本自适应优化流程图。

#### **【具体实施方式】**

[0014] 下面将结合附图和实施例，对本发明作进一步的详细说明，以使本领域的技术人员可以更好地理解本发明的技术方案。

[0015] 在本发明的一个实施例中，参照图1所示的系统整体架构，首先执行外部语义风险预处理步骤。用户的输入文本，例如一段包含潜在恶意指令的提示，被首先送入配置于主大语言模型前端的**预处理模块**。该模块的核心是一个轻量级的意图分类模型，例如一个经过蒸馏和量化的DistilBERT模型，以确保低延迟和高效率。该模型经过专门训练，能够识别多种典型的攻击模式，包括但不限于**指令冲突意图**、**角色扮演诱导意图**以及**假设情景规避意图**。模型对输入文本进行深度语义分析后，会输出一个多维度的概率向量，每一维度对应一种攻击意图的置信度。随后，通过对这些概率进行加权求和或取最大值的策略，生成一个被归一化到[0, 1]区间的**初始风险评分** $S_{ext}$。该评分直观地量化了用户输入在语义层面所表现出的攻击倾向性，为后续的协同裁决提供了第一道防线的判断依据。

[0016] 接着，当用户输入通过预处理模块后，无论其初始风险评分高低，均被送入主大语言模型进行正常的推理生成，同时，系统执行内部状态实时监控步骤。与主模型深度耦合的**监控模块**被激活，开始对模型在推理过程中的内部计算状态进行实时、逐词元（token-by-token）的监控。该模块的核心在于捕捉由恶意输入引发的、在外部文本流中难以察觉的内部“神经活动”异常。本实施例中，监控模块重点关注两个关键内部状态指标。第一个指标是**注意力分布熵**。在Transformer架构中，自注意力机制决定了模型在生成每个词元时对输入序列各部分的关注度权重。在处理恶意输入时，模型往往会被迫将其注意力异常地、高度地集中在攻击者植入的恶意指令片段上，而忽略系统预设的安全准则。通过实时提取关键自注意力层的权重矩阵并计算其香农熵，可以量化这种注意力分布的集中或混乱程度。一个相较于正常对话基线（例如，一个预先通过海量良性对话数据统计出的均值和标准差）急剧下降或持续处于极低水平的熵值，是模型注意力被劫持的强烈信号。第二个指标是**层激活范数**。为了绕过固有的安全限制，恶意输入常常迫使模型进入其在正常训练数据中极为罕见的“状态空间”，这会直观地体现在某些Transformer层的输出激活值上出现异常的幅值或分布。监控模块通过计算这些激活向量的L2范数，并与预先标定的基线范数进行比较，能够有效检测出这种状态偏离。

[0017] 监控模块根据上述两个指标的实时偏离度，通过一个预设的加权函数，例如 $S_{int}(t) = \sigma(w_{ent} \cdot D_{entropy}(t) + w_{norm} \cdot D_{norm}(t))$，动态地生成一个综合的、同样归一化到[0, 1]区间的**内部异常评分** $S_{int}$。其中，$D_{entropy}$ 和 $D_{norm}$ 分别代表注意力熵和激活范数相对于基线的标准化偏离度（如Z-score），$w_{ent}$ 和 $w_{norm}$ 为可调权重，$\sigma(\cdot)$ 为Sigmoid函数，用于将评分映射到概率区间。此评分精确地反映了模型内部状态的紊乱程度。

[0018] 然后，系统执行协同裁决与动态响应步骤，参照图2所示的协同裁决逻辑。作为系统决策中枢的**裁决模块**，会实时接收来自预处理模块的静态初始风险评分 $S_{ext}$ 和来自监控模块的动态内部异常评分 $S_{int}$。裁决模块的核心是一个预设的协同决策矩阵或一个动态决策函数。它并非孤立地看待任一评分，而是对二者进行联合判断，以实现优势互补和交叉验证。例如，当 $S_{ext}$ 和 $S_{int}$ 均低于预设的低风险阈值（如0.3）时，系统高置信度地判定该请求为安全，并允许模型正常输出。当两个评分均高于高风险阈值（如0.8）时，系统判定为一次明确的攻击，并立即中断模型的生成过程，向用户返回预设的安全提示。

[0019] 本发明最具创新性的裁决场景在于处理评分不一致的情况。当初始风险评分 $S_{ext}$ 很低（语义看似无害），但内部异常评分 $S_{int}$ 却异常高时，这标志着系统发现了一种传统“黑箱”防御完全无法识别的新型未知攻击。这种攻击在语义上高度伪装，但却能成功扰乱模型的内部状态。裁决模块会立即拦截此类请求，并将该输入与触发高异常的内部状态数据（如对应的注意力矩阵快照）作为一个高价值样本进行标记和存储。反之，当 $S_{ext}$ 很高而 $S_{int}$ 始终保持在正常水平时，这表明一次明显的攻击尝试被模型自身的鲁棒性成功抵御，其内部状态并未发生紊乱。裁决模块可选择放行输出，但会生成一条高优先级日志，记录此次成功的防御案例，供后续模型鲁棒性分析使用。***（图和权要结合写一遍）***

[0020] 最后，参照图3所示的自适应优化流程，对于被裁决模块标记为“新型未知攻击”的样本，系统将其自动归档至一个专用的攻击样本增强数据集中。该数据集用于定期或通过在线学习的方式，对预处理模块中的轻量级意图分类模型进行重新训练或微调。通过这种方式，系统能够从被成功拦截的未知攻击中学习，不断提升其前端语义识别的能力，形成一个闭环的、自我进化的动态防御体系，从而对未来出现的同类或变体攻击具备更强的免疫力。

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTgyNjI2NjQyMiwxMDc3MTk1OTIzLDQ5NT
E4NTk4NCwzOTM1MTk2OTAsLTkyNjQ0MzA4LC0xODUxNDgxMzgs
LTIwMDUxMzA1NjksNzg1MTA0Mzk3LDExOTIxMjE1Nl19
-->