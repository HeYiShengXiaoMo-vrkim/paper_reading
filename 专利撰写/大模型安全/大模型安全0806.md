## 标题
### **一种基于内部状态与外部语义协同感知的大语言模型动态安全监测方法**
## 摘要
本发明提出一种基于内部状态与外部语义协同感知的大语言模型动态安全监测方法。该方法首先通过外部语义感知模块对用户输入进行高风险意图分析，生成初始风险评分；其次，在模型推理时，通过内部状态监控模块实时监测其注意力分布熵和层激活范数等内部关键状态，生成内部异常评分；最后，动态判断裁决模块协同分析内外风险信号，结合预设的协同决策逻辑进行综合评判，并执行拦截、放行或告警等响应动作。本发明通过内外协同感知，有效解决了传统“黑箱”式防御无法应对语义隐晦攻击的问题，能显著提升对未知和复杂攻击的识别准确率与响应及时性。

## 权利要求书

1.  一种基于内部状态与外部语义协同感知的大语言模型动态安全监测方法包括以下步骤：
    (a) **外部语义风险预处理**：对一个用户输入的**完整文本片段**进行一次性的、前置的语义风险分析，以识别其中是否存在至少一种预定义的恶意攻击意图，并基于该分析结果，生成一个在该次请求的后续处理中保持不变的**初始风险评分**；
    (b) **内部状态实时监控**：在主大语言模型根据所述用户输入进行**逐词元**的自回归推理以生成输出内容的过程中，通过与所述主大语言模型深度耦合的监控模块，实时、同步地监控所述主大语言模型内部的一个或多个预定Transformer计算层的关键状态指标，以捕捉由所述用户输入引发的内部计算状态异常，并为**每一个正在生成的词元**生成一个动态的**内部异常评分**；
    (c) **协同裁决与动态响应**：在**每一个词元生成时**，通过动态判断裁决模块，基于所述不变的初始风险评分和当前词元对应的动态内部异常评分，利用预设的协同决策逻辑进行综合风险评判，并根据该评判结果，实时地决定是允许继续生成下一个词元，还是立即中断整个生成过程。

2.  根据权利要求1所述的方法，其特征在于，所述步骤(a)中，所述外部语义风险预处理具体包括：
    部署一个轻量级意图分类模型，该模型预先通过包含已知攻击模式的样本集进行训练，所述攻击模式至少包括**指令冲突意图**、**角色扮演诱导意图**以及**假设情景规避意图**；
    利用所述模型对用户输入文本进行前向传播，得到一个多维度的置信度概率向量，其中每一维度对应一种攻击意图的发生概率；
    通过对所述置信度概率向量中的各维度概率值应用一个预设的聚合函数，生成被归一化到[0, 1]区间的所述初始风险评分 $S_{ext}$。

3.  根据权利要求1所述的方法，其特征在于，所述步骤(b)中，所述内部关键状态指标至少包括**注意力分布熵**和**层激活范数**；所述生成内部异常评分的步骤具体为：
    首先，计算所述注意力分布熵和所述层激活范数相对于预先通过大量正常对话数据统计出的基线分布的标准化偏离度；
    然后，通过对所述标准化偏离度进行加权求和，得到一个综合偏离值；
    最后，利用一个非线性激活函数将所述综合偏离值映射到[0, 1]区间，以生成所述内部异常评分 $S_{int}(t)$。

4.  根据权利要求3所述的方法，其特征在于，所述**注意力分布熵**的监控具体为：在模型生成每个词元时，提取其Transformer架构中**最后一层自注意力层**的权重矩阵，并计算所述权重矩阵的香农熵，以量化模型在生成当前词元时对其上下文关注点的分布集中程度。

5.  根据权利要求3所述的方法，其特征在于，所述**层激活范数**的监控具体为：在模型推理生成每个词元时，获取其Transformer架构中**最后一层前馈网络**的输出激活值向量，并计算所述向量的**L2范数**，其中L2范数为所述向量中各元素平方和的平方根，用以衡量模型在输出最终词元概率分布前的神经元激活强度。

6.  根据权利要求1所述的方法，其特征在于，所述步骤(c)中的协同决策逻辑具体为：
    在生成每个词元 $t$ 时，计算一个即时的最终裁决分数 $S_{final}(t)$，其计算公式为：
    $$
    S_{final}(t) = \lambda \cdot S_{ext} + (1-\lambda) \cdot S_{int}(t)
    $$
    其中，$S_{ext}$ 为所述固定的初始风险评分，$S_{int}(t)$ 为生成第 $t$ 个词元时的内部异常评分，$\lambda$ 为一个用于平衡外部语义风险与内部状态异常重要性的预设权重因子，其取值范围为[0.4, 0.6]。

7.  根据权利要求6所述的方法，其特征在于，所述动态响应动作具体为：
    在生成每个词元 $t$ 时，将所计算出的最终裁决分数 $S_{final}(t)$ 与一个预设的高风险阈值 $\theta_{high}$ 进行实时比较；
    若 $S_{final}(t)$ 的值首次超过所述高风险阈值 $\theta_{high}$，则立即中断所述主大语言模型的生成过程，并向用户返回一个预设的安全提示；
    若在整个生成过程结束时，$S_{final}(t)$ 的值均未超过所述高风险阈值 $\theta_{high}$，则允许模型的完整输出；
    其中，所述高风险阈值 $\theta_{high}$ 的取值范围为[0.8, 0.9]。

8.  根据权利要求7所述的方法，其特征在于，所述方法还包括一个用于发现并处理**新型未知攻击**的特定逻辑，该逻辑被定义为：
    当所述初始风险评分 $S_{ext}$ 低于一个预设的低风险阈值 $\theta_{low}$，同时在生成某个词元 $t$ 时，所述最终裁决分数 $S_{final}(t)$ 首次超过所述高风险阈值 $\theta_{high}$，则将该次请求判定为一次新型未知攻击，并立即中断模型的生成过程。

```
9.  根据权利要求8所述的方法，其特征在于，所述方法还包括一个**防御系统自适应优化**的步骤，该步骤在判定发生新型未知攻击后被自动或半自动触发，具体包括：
    将触发该判定的用户输入文本，以及由内部状态监控模块捕获到的、导致内部异常评分增高的具体内部关键状态指标数据（包括但不限于异常的注意力矩阵和激活值向量），进行打包并存储，以形成一个攻击样本增强数据集；
    利用所述攻击样本增强数据集中新增的样本，对权利要求2中所述的轻量级意图分类模型进行重新训练或在线微调，以提升其未来对同类或变体的新型未知攻击的语义识别能力，从而形成一个闭环的、自我进化的防御体系。
```

10. 一种基于内部状态与外部语义协同感知的大语言模型动态安全监测系统，其特征在于，所述系统被配置为执行权利要求1至9中任一项所述的方法，并包括：
    一个**外部语义感知模块**，用于生成所述初始风险评分；
    一个**内部状态监控模块**，与主大语言模型进行深度耦合，用于生成所述动态的内部异常评分；
    一个**动态判断裁决模块**，用于执行所述协同决策逻辑并输出控制指令；
## 技术说明书


#### **【技术领域】**

[0001] 本发明属于人工智能安全技术领域，尤其涉及一种用于检测和防御针对大语言模型的恶意攻击，特别是提示注入和越狱攻击的系统及方法。

#### **【背景技术】**

[0002] 近年来，以Transformer架构为基础的大语言模型（LLM）取得了突破性进展，并在自然语言处理、代码生成、智能客服、内容创作等众多领域展现出巨大的应用潜力。然而，随着其能力的增强和应用的普及，其面临的安全威胁也日益严峻。

[0003] 目前，针对大语言模型的攻击主要表现为两种形式：一是提示注入，攻击者通过在用户输入中植入恶意指令，意图篡改或覆盖模型开发者预设的系统级指令，从而劫持模型的任务流，使其执行非预期甚至有害的操作。二是越狱，攻击者通过构建复杂的对话场景、进行角色扮演诱导或利用模型的逻辑漏洞，绕过其安全与道德准则，迫使其生成被禁止的内容，如暴力、歧视性言论或非法活动指南。

[0004] 现有技术方案普遍将大语言模型视作一个不可观测的“黑箱”，防御措施仅停留在其外部的文本流层面。这种方式无法感知到模型在处理恶意输入时，其内部计算状态发生的微妙而关键的变化。因此，当面对精心构造的、语义隐晦的复杂攻击时，这些防御手段往往显得力不从心，难以提供可靠、前瞻性的安全保障。

#### **【发明内容】**

[0005] 针对上述技术的不足，本发明的目的在于解决现有技术中存在的表层防御易被绕过、无法感知内部状态以及对未知攻击泛化能力差的问题。

[0006] 为实现上述目的，本发明采取的技术方案如下：

[0007] 所述一种基于内部状态与外部语义协同感知的大语言模型动态安全监测方法，包括以下步骤：  
第一步，通过外部语义感知模块对**整个用户输入文本片段**进行一次性的外部语义风险预处理，以分析其中是否存在恶意攻击意图，并据此生成一个在后续生成过程中保持不变的初始风险评分；
第二步，在主大语言模型处理用户输入并进行**逐词元**的自回归推理以生成内容的过程中，通过内部状态监控模块实时监控其内部关键状态指标的异常，并为**每一个正在生成的词元**生成一个动态的内部异常评分；
第三步，通过动态判断裁决模块，在**每一个词元生成时**，基于所述不变的初始风险评分和当前词元对应的动态内部异常评分，利用预设的协同决策逻辑进行综合评判，并根据评判结果执行拦截、放行或告警的动态响应动作。

[0008] 所述外部语义感知模块中生成初始风险评分 $S_{ext}$ 的步骤具体为：首先，利用一个轻量级意图分类模型对用户输入文本 $I$ 进行分析，输出一个对应于指令冲突、角色扮演等多种攻击意图的置信度概率向量；然后，通过对该概率向量进行加权求和或取最大值的策略得到评分，其计算可表示为 $S_{ext} = f(I; \theta_{cls})$，其中$f(\cdot)$为分类模型，$\theta_{cls}$为模型参数。

[0009] 所述内部状态监控模块监控的内部关键状态指标至少包括注意力分布熵和层激活范数。所述内部异常评分 $S_{int}$ 的生成方式为：首先，计算各指标相对于预先标定的正常基线的偏离度，例如，注意力分布熵的偏离度 $D_{entropy}$ 和层激活范数的偏离度 $D_{norm}$；然后，通过对各偏离度进行加权求和得到一个综合偏离值，即 $w_{ent} \cdot D_{entropy}(t) + w_{norm} \cdot D_{norm}(t)$；最后，利用Sigmoid函数 $\sigma(\cdot)$ 将该综合偏离值映射到[0, 1]区间以生成评分 $S_{int}(t)$。

[0010] 进一步地，为了提高监测的精确性和响应的及时性，所述注意力分布熵和层激活范数的监控位置被设定在主大语言模型Transformer架构的特定层级。具体而言，监控模块提取模型**最后一层自注意力层**的权重矩阵以计算注意力分布熵，因为该层的注意力权重最直接地反映了模型在生成最终词元前的关注点分布。同时，监控模块获取**最后一层前馈网络**的输出激活值以计算其L2范数，因为该层的激活状态是模型输出最终词元概率分布前的最后一个高维特征表示，对模型的最终决策行为具有决定性影响。通过监控这些最终决策前的关键节点，能够在不影响模型正常推理流程的前提下，以最小的性能开销实现最有效的风险感知。

[0011] 可选地，所述动态判断裁决模块的协同决策逻辑通过计算一个最终裁决分数 $S_{final}$ 来实现，其计算公式为：$S_{final}(t) = \lambda \cdot S_{ext} + (1-\lambda) \cdot S_{int}(t)$。其中，$S_{ext}$ 为固定的初始风险评分，$S_{int}(t)$ 为生成第 $t$ 个词元时的内部异常评分，$\lambda$ 为平衡外部与内部风险的预设权重因子，取值范围优选为[0.4, 0.6]。裁决模块在生成每个词元t时，都会计算一次$S_{final}(t)$，并将其与预设的低风险阈值 $\theta_{low}$（优选范围[0.3, 0.5]）和高风险阈值 $\theta_{high}$（优选范围[0.8, 0.9]）进行比较。

[0012] 可选地，所述方法还包括一个防御系统自适应优化的步骤。该步骤在系统判定发生新型未知攻击（即 $S_{ext}$ 低于 $\theta_{low}$ 但存在某个时刻 $t$ 使得 $S_{final}(t)$ 高于 $\theta_{high}$）时被触发。其核心在于，将被判定为新型攻击的用户输入及其对应的、导致高内部异常评分的内部状态数据打包存储，形成一个攻击样本增强数据集。该数据集随后被用于对外部语义感知模块中的轻量级意图分类模型进行重新训练或在线微调，例如采用梯度下降算法 $\theta_{cls}^{new} = \theta_{cls}^{old} - \eta \cdot \nabla_{\theta_{cls}} L(\theta_{cls}^{old})$ 进行权重更新，从而使防御系统能够从实战中学习，持续提升对未来未知威胁的识别能力。

#### 【附图说明】

[0013] 图1为本发明所述的大语言模型动态安全监测系统的整体架构示意图。
[0014] 图2为本发明所述的协同裁决逻辑示意图。
[0015] 图3为本发明所述的未知攻击样本自适应优化流程图。

#### 【具体实施方式】

[0016] 下面将结合附图，对本发明的技术方案作进一步的详细说明。

[0017] 参照图1，本发明所述的动态安全监测方法的实施流程始于**外部语义感知模块**，该模块对接收到的**整个用户输入文本片段**进行一次性的、全局的语义风险分析。其内部署的轻量级意图分类模型，能够高效地识别其中是否蕴含指令冲突、角色扮演诱导等恶意攻击模式。完成分析后，该模块会输出一个量化的**初始风险评分** $S_{ext}$，此评分在后续的整个生成过程中保持不变，作为对输入文本宏观风险的评估。

[0018] 在外部语义感知模块完成处理后，用户输入被送入**主大语言模型**。模型开始进行**逐词元**的自回归推理以生成响应内容。在此过程中，**内部状态监控模块**被激活并与主大语言模型并行工作，对**每一个正在生成的词元**进行实时的内部状态监控。该模块会挂接到主大语言模型Transformer架构的特定关键层级，优选为**最后一层自注意力层**和**最后一层前馈网络**。对于前者，监控模块提取其在生成每个词元时的注意力权重矩阵并计算其香农熵；对于后者，则提取其输出激活向量并计算其L2范数。这些实时计算出的指标值会与预先标定好的基线范围进行比较，任何显著的偏离都将被量化，并最终为**当前生成的词元**汇聚成一个动态变化的**内部异常评分** $S_{int}(t)$。

[0019] 参照图2所示的协同裁决逻辑，**动态判断裁决模块**是整个防御体系的决策中枢，其决策粒度同样是**逐词元**的。在模型生成每一个词元 $t$ 时，该模块都会执行一次决策。它接收来自外部语义感知模块的**固定**初始风险评分 $S_{ext}$ 和来自内部状态监控模块**当前时刻**的内部异常评分 $S_{int}(t)$。通过一个协同决策算法，例如计算一个综合的**最终裁决分数** $S_{final}(t) = \lambda \cdot S_{ext} + (1-\lambda) \cdot S_{int}(t)$，该模块对当前生成步骤的风险进行评估。一旦在任何一个词元的生成点上，$S_{final}(t)$ 的值超过了预设的高风险阈值，裁决模块就会立即输出拦截指令，中断整个生成过程，从而实现即时响应和精准干预。

[0020] 参照图3，本发明的自适应优化能力构成了防御的闭环。当动态判断裁决模块识别并拦截了一次“新型未知攻击”时，系统会自动触发**自适应优化单元**。该单元负责将这次攻击的用户输入文本，以及由内部状态监控模块捕获到的、导致高异常评分的具体内部状态数据进行打包，并存入一个专门的**攻击样本增强数据集**。该数据集作为宝贵的负样本资源，被用于定期地或实时地对外部语义感知模块中的意图分类模型进行微调或重新训练。这个过程使得防御系统能够从实战中捕获的未知威胁中学习，不断提升其前端宏观语义识别的能力，从而实现防御能力的持续进化和对未来攻击的更好免疫。

## 附图
```
[0013] 图1为本发明所述的大语言模型动态安全监测系统的整体架构示意图。  
[0014] 图2为本发明所述的协同裁决逻辑示意图。  
[0015] 图3为本发明所述的未知攻击样本自适应优化流程图。
```
![输入图片说明](/imgs/2025-08-09/90xY34BOr20CVUA5.png)
![输入图片说明](/imgs/2025-08-09/Q9Ndo7LMXBxKNylw.png)
![输入图片说明](/imgs/2025-08-09/ontSY8m568M8xp95.png)
<!--stackedit_data:
eyJoaXN0b3J5IjpbODk2NzE3ODk5LDE0MzQxMjU3OTIsODYwMD
YwMTUwLC01OTUxNzQ0MDAsLTEyMDkzOTExMTgsLTE5Mjc5ODU2
NTUsLTEwNzgwMDMxODgsNTExODg4ODc1LC02MjIwOTE4MywtMz
kzNDkwOTE2LDEwODMzMzk1MTEsNjQyNzYxMTc2LDQ3NzQ3Nzg5
MF19
-->